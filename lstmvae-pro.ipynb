{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "etniX_KTlJ5U",
    "pycharm": {
     "name": "#%% md\n"
    }
   },
   "source": [
    "# LSTM-VAE pro"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "outputs": [],
   "source": [
    "from model.bagging_lstmvae_pro import *\n",
    "import torch.utils.data as data_utils\n",
    "from utils.eval_methods import *\n",
    "from sklearn import preprocessing\n",
    "\n",
    "device = get_default_device()\n",
    "\n",
    "min_max_scaler = preprocessing.MinMaxScaler()\n",
    "# Read data\n",
    "normal = pd.read_csv(\"data/SWaT/SWaT_Dataset_Normal_v1.csv\", nrows=10000)  # , nrows=1000)\n",
    "normal = normal.drop([\"Timestamp\", \"Normal/Attack\"], axis=1)\n",
    "# Transform all columns into float64\n",
    "for i in list(normal):\n",
    "    normal[i] = normal[i].apply(lambda x: str(x).replace(\",\", \".\"))\n",
    "normal = normal.astype(float)\n",
    "# 数据归一化\n",
    "x = normal.values\n",
    "x_scaled = min_max_scaler.fit_transform(x)\n",
    "normal = pd.DataFrame(x_scaled)\n",
    "\n",
    "# Read data\n",
    "attack = pd.read_csv(\"data/SWaT/SWaT_Dataset_Attack_v0.csv\", sep=\";\", nrows=10000)  # , nrows=1000)\n",
    "labels = [float(label != 'Normal') for label in attack[\"Normal/Attack\"].values]\n",
    "attack = attack.drop([\"Timestamp\", \"Normal/Attack\"], axis=1)\n",
    "# Transform all columns into float64\n",
    "for i in list(attack):\n",
    "    attack[i] = attack[i].apply(lambda x: str(x).replace(\",\", \".\"))\n",
    "attack = attack.astype(float)\n",
    "x = attack.values\n",
    "x_scaled = min_max_scaler.transform(x)\n",
    "attack = pd.DataFrame(x_scaled)"
   ],
   "metadata": {
    "collapsed": false,
    "pycharm": {
     "name": "#%%\n"
    }
   }
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "outputs": [],
   "source": [
    "############## windows ###################\n",
    "window_size = 12\n",
    "# np.arange(window_size)[None, :] 1*12 (0,1,2,3,4,5,6,7,8,9,10,11)一行12列\n",
    "# np.arange(normal.shape[0] - window_size)[:, None] (1000-12)*1 (0,1,2,3,4,5...) 988列，每列递增\n",
    "# np.arange(window_size)[None, :] + np.arange(normal.shape[0] - window_size)[:, None] (1000-12)*12\n",
    "windows_normal = normal.values[np.arange(window_size)[None, :] + np.arange(attack.shape[0] - window_size)[:, None]]\n",
    "windows_attack = attack.values[np.arange(window_size)[None, :] + np.arange(attack.shape[0] - window_size)[:, None]]\n",
    "\n",
    "windows_labels=[]\n",
    "for i in range(len(labels)-window_size):\n",
    "    windows_labels.append(list(np.int_(labels[i:i+window_size])))\n",
    "y_test = [1.0 if (np.sum(window) > 0) else 0 for window in windows_labels]\n",
    "y_test = np.array(y_test)"
   ],
   "metadata": {
    "collapsed": false,
    "pycharm": {
     "name": "#%%\n"
    }
   }
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "outputs": [],
   "source": [
    "############## training ###################\n",
    "BATCH_SIZE = 500\n",
    "N_EPOCHS = 10\n",
    "N = 5 * round((normal.shape[1] / 3) / 5)  # 10 for both bootstrap sample size and number of estimators\n",
    "decoder_layers = 2  # number of hidden layers for each decoder\n",
    "z = int((N / 2) - 1)  # size of latent space\n",
    "\n",
    "windows_normal_train = windows_normal[:int(np.floor(.8 * windows_normal.shape[0]))]\n",
    "windows_normal_val = windows_normal[int(np.floor(.8 * windows_normal.shape[0])):int(np.floor(windows_normal.shape[0]))]\n",
    "\n",
    "train_loader = torch.utils.data.DataLoader(data_utils.TensorDataset(\n",
    "    torch.from_numpy(windows_normal_train).float().view(\n",
    "        ([windows_normal_train.shape[0], windows_normal_train.shape[1], windows_normal_train.shape[2]]))\n",
    "), batch_size=BATCH_SIZE, shuffle=False, num_workers=0)\n",
    "\n",
    "val_loader = torch.utils.data.DataLoader(data_utils.TensorDataset(\n",
    "    torch.from_numpy(windows_normal_val).float().view(\n",
    "        ([windows_normal_val.shape[0], windows_normal_train.shape[1], windows_normal_train.shape[2]]))\n",
    "), batch_size=BATCH_SIZE, shuffle=False, num_workers=0)\n",
    "\n",
    "test_loader = torch.utils.data.DataLoader(data_utils.TensorDataset(\n",
    "    torch.from_numpy(windows_attack).float().view(\n",
    "        ([windows_attack.shape[0], windows_attack.shape[1], windows_attack.shape[2]]))\n",
    "), batch_size=BATCH_SIZE, shuffle=False, num_workers=0)"
   ],
   "metadata": {
    "collapsed": false,
    "pycharm": {
     "name": "#%%\n"
    }
   }
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "outputs": [],
   "source": [
    "model = BaggingLstmVAE(time_step=window_size,\n",
    "                       input_dim=normal.shape[1],\n",
    "                       hidden_size=N,\n",
    "                       n_estimators=N,\n",
    "                       max_features=N,\n",
    "                       latent_dim=z,\n",
    "                       decoding_depth=decoder_layers)\n",
    "for i in range(model.n_estimators):\n",
    "    model.LSTMVAEs[i] = to_device(model.LSTMVAEs[i], device)\n",
    "    model.DivLstmVAEs[i] = to_device(model.DivLstmVAEs[i], device)"
   ],
   "metadata": {
    "collapsed": false,
    "pycharm": {
     "name": "#%%\n"
    }
   }
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "VAE encoder开始训练\n",
      "Epoch[0]  loss_vae: 19.3010\n",
      "Epoch[1]  loss_vae: 4.3951\n",
      "Epoch[2]  loss_vae: 0.6489\n",
      "Epoch[3]  loss_vae: 0.2767\n",
      "Epoch[4]  loss_vae: 0.1676\n",
      "Epoch[5]  loss_vae: 0.1181\n",
      "Epoch[6]  loss_vae: 0.0994\n",
      "Epoch[7]  loss_vae: 0.0914\n",
      "Epoch[8]  loss_vae: 0.0877\n",
      "Epoch[9]  loss_vae: 0.0849\n",
      "lower decoder, upper decoder开始训练\n",
      "Epoch[0]  loss_low: 0.1924, loss_high: 0.2121\n",
      "Epoch[1]  loss_low: 0.1839, loss_high: 0.2035\n",
      "Epoch[2]  loss_low: 0.1742, loss_high: 0.1934\n",
      "Epoch[3]  loss_low: 0.1625, loss_high: 0.1814\n",
      "Epoch[4]  loss_low: 0.1490, loss_high: 0.1673\n",
      "Epoch[5]  loss_low: 0.1338, loss_high: 0.1520\n",
      "Epoch[6]  loss_low: 0.1174, loss_high: 0.1359\n",
      "Epoch[7]  loss_low: 0.1008, loss_high: 0.1203\n",
      "Epoch[8]  loss_low: 0.0849, loss_high: 0.1063\n",
      "Epoch[9]  loss_low: 0.0701, loss_high: 0.0945\n"
     ]
    }
   ],
   "source": [
    "history = training(N_EPOCHS, model, train_loader)"
   ],
   "metadata": {
    "collapsed": false,
    "pycharm": {
     "name": "#%%\n"
    }
   }
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "outputs": [],
   "source": [
    "lower, upper = testing(model, test_loader)"
   ],
   "metadata": {
    "collapsed": false,
    "pycharm": {
     "name": "#%%\n"
    }
   }
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[0.99738562 1.         0.99607843 0.99607843 0.99738562 0.99607843\n",
      " 1.         0.99738562 0.99738562 0.99869281 0.99738562 0.99869281\n",
      " 0.99607843 0.99346405 0.99738562 0.99346405 0.99738562 0.99084967\n",
      " 0.99084967 0.99738562 0.99869281 0.99738562 0.99869281 0.99477124\n",
      " 0.98954248 0.99477124 0.99738562 0.99869281 1.         1.\n",
      " 0.99738562 0.99869281 0.99084967 0.99869281 0.99215686 0.99869281\n",
      " 0.99607843 0.99607843 0.99607843 0.99869281 0.99738562 0.99607843\n",
      " 0.99477124 0.99607843 1.         0.99738562 1.         0.99607843\n",
      " 0.99869281 0.99738562 0.99869281 0.99869281 1.         0.99607843\n",
      " 0.99869281 0.99477124 0.99869281 0.99869281 0.99215686 0.99869281\n",
      " 0.99869281 0.99738562 0.99738562 0.99738562 0.99346405 0.99607843\n",
      " 0.99477124 0.99084967 0.99738562 0.99215686 0.99477124 0.99869281\n",
      " 0.99738562 0.99869281 0.99607843 1.         0.99607843 0.99215686\n",
      " 0.99738562 0.99607843 0.99738562 0.99738562 0.99607843 0.99869281\n",
      " 0.99738562 0.99869281 0.99869281 0.99869281 0.99607843 1.\n",
      " 0.99607843 0.99346405 0.99084967 0.99477124 0.99607843 0.99477124\n",
      " 0.99215686 0.99607843 0.99607843 1.        ]\n",
      "search range:  0 1\n",
      "cur thr:  0.001 [0.4436272443816195, 0.28504205017516815, 0.9999999964875307, 2847.0, 0.0, 7141.0, 0.0, 0.0] [0.4436272443816195, 0.28504205017516815, 0.9999999964875307, 2847.0, 0.0, 7141.0, 0.0, 0.0] 0.001\n",
      "cur thr:  0.05100000000000004 [0.4436272443816195, 0.28504205017516815, 0.9999999964875307, 2847.0, 0.0, 7141.0, 0.0, 0.0] [0.4436272443816195, 0.28504205017516815, 0.9999999964875307, 2847.0, 0.0, 7141.0, 0.0, 0.0] 0.001\n",
      "cur thr:  0.10100000000000008 [0.4436272443816195, 0.28504205017516815, 0.9999999964875307, 2847.0, 0.0, 7141.0, 0.0, 0.0] [0.4436272443816195, 0.28504205017516815, 0.9999999964875307, 2847.0, 0.0, 7141.0, 0.0, 0.0] 0.001\n",
      "cur thr:  0.1510000000000001 [0.4436272443816195, 0.28504205017516815, 0.9999999964875307, 2847.0, 0.0, 7141.0, 0.0, 0.0] [0.4436272443816195, 0.28504205017516815, 0.9999999964875307, 2847.0, 0.0, 7141.0, 0.0, 0.0] 0.001\n",
      "cur thr:  0.20100000000000015 [0.4436272443816195, 0.28504205017516815, 0.9999999964875307, 2847.0, 0.0, 7141.0, 0.0, 0.0] [0.4436272443816195, 0.28504205017516815, 0.9999999964875307, 2847.0, 0.0, 7141.0, 0.0, 0.0] 0.001\n",
      "cur thr:  0.25100000000000017 [0.4436272443816195, 0.28504205017516815, 0.9999999964875307, 2847.0, 0.0, 7141.0, 0.0, 0.0] [0.4436272443816195, 0.28504205017516815, 0.9999999964875307, 2847.0, 0.0, 7141.0, 0.0, 0.0] 0.001\n",
      "cur thr:  0.3010000000000002 [0.4436272443816195, 0.28504205017516815, 0.9999999964875307, 2847.0, 0.0, 7141.0, 0.0, 0.0] [0.4436272443816195, 0.28504205017516815, 0.9999999964875307, 2847.0, 0.0, 7141.0, 0.0, 0.0] 0.001\n",
      "cur thr:  0.35100000000000026 [0.4436272443816195, 0.28504205017516815, 0.9999999964875307, 2847.0, 0.0, 7141.0, 0.0, 0.0] [0.4436272443816195, 0.28504205017516815, 0.9999999964875307, 2847.0, 0.0, 7141.0, 0.0, 0.0] 0.001\n",
      "cur thr:  0.4010000000000003 [0.4436272443816195, 0.28504205017516815, 0.9999999964875307, 2847.0, 0.0, 7141.0, 0.0, 0.0] [0.4436272443816195, 0.28504205017516815, 0.9999999964875307, 2847.0, 0.0, 7141.0, 0.0, 0.0] 0.001\n",
      "cur thr:  0.45100000000000035 [0.4436272443816195, 0.28504205017516815, 0.9999999964875307, 2847.0, 0.0, 7141.0, 0.0, 0.0] [0.4436272443816195, 0.28504205017516815, 0.9999999964875307, 2847.0, 0.0, 7141.0, 0.0, 0.0] 0.001\n",
      "cur thr:  0.5010000000000003 [0.4436272443816195, 0.28504205017516815, 0.9999999964875307, 2847.0, 0.0, 7141.0, 0.0, 0.0] [0.4436272443816195, 0.28504205017516815, 0.9999999964875307, 2847.0, 0.0, 7141.0, 0.0, 0.0] 0.001\n",
      "cur thr:  0.5510000000000004 [0.4436272443816195, 0.28504205017516815, 0.9999999964875307, 2847.0, 0.0, 7141.0, 0.0, 0.0] [0.4436272443816195, 0.28504205017516815, 0.9999999964875307, 2847.0, 0.0, 7141.0, 0.0, 0.0] 0.001\n",
      "cur thr:  0.6010000000000004 [0.4436272443816195, 0.28504205017516815, 0.9999999964875307, 2847.0, 0.0, 7141.0, 0.0, 0.0] [0.4436272443816195, 0.28504205017516815, 0.9999999964875307, 2847.0, 0.0, 7141.0, 0.0, 0.0] 0.001\n",
      "cur thr:  0.6510000000000005 [0.4436272443816195, 0.28504205017516815, 0.9999999964875307, 2847.0, 0.0, 7141.0, 0.0, 0.0] [0.4436272443816195, 0.28504205017516815, 0.9999999964875307, 2847.0, 0.0, 7141.0, 0.0, 0.0] 0.001\n",
      "cur thr:  0.7010000000000005 [0.4436272443816195, 0.28504205017516815, 0.9999999964875307, 2847.0, 0.0, 7141.0, 0.0, 0.0] [0.4436272443816195, 0.28504205017516815, 0.9999999964875307, 2847.0, 0.0, 7141.0, 0.0, 0.0] 0.001\n",
      "cur thr:  0.7510000000000006 [0.4436272443816195, 0.28504205017516815, 0.9999999964875307, 2847.0, 0.0, 7141.0, 0.0, 0.0] [0.4436272443816195, 0.28504205017516815, 0.9999999964875307, 2847.0, 0.0, 7141.0, 0.0, 0.0] 0.001\n",
      "cur thr:  0.8010000000000006 [0.4436272443816195, 0.28504205017516815, 0.9999999964875307, 2847.0, 0.0, 7141.0, 0.0, 0.0] [0.4436272443816195, 0.28504205017516815, 0.9999999964875307, 2847.0, 0.0, 7141.0, 0.0, 0.0] 0.001\n",
      "cur thr:  0.8510000000000006 [0.4436272443816195, 0.28504205017516815, 0.9999999964875307, 2847.0, 0.0, 7141.0, 0.0, 0.0] [0.4436272443816195, 0.28504205017516815, 0.9999999964875307, 2847.0, 0.0, 7141.0, 0.0, 0.0] 0.001\n",
      "cur thr:  0.9010000000000007 [0.4436272443816195, 0.28504205017516815, 0.9999999964875307, 2847.0, 0.0, 7141.0, 0.0, 0.0] [0.4436272443816195, 0.28504205017516815, 0.9999999964875307, 2847.0, 0.0, 7141.0, 0.0, 0.0] 0.001\n",
      "cur thr:  0.9510000000000007 [0.4436272443816195, 0.28504205017516815, 0.9999999964875307, 2847.0, 0.0, 7141.0, 0.0, 0.0] [0.4436272443816195, 0.28504205017516815, 0.9999999964875307, 2847.0, 0.0, 7141.0, 0.0, 0.0] 0.001\n",
      "[0.8602458882489766, 0.7547720022407953, 0.9999999964875307, 2847.0, 6216.0, 925.0, 0.0, 6.499891668472192] 0.9990000000000008\n"
     ]
    }
   ],
   "source": [
    "# 点调整法\n",
    "windows_attack = windows_attack[:, -1, :]\n",
    "attack_tiles = np.tile(windows_attack.reshape(windows_attack.shape[0], 1, windows_attack.shape[1]), (1, N, 1))\n",
    "result = np.where((attack_tiles < lower.numpy()) | (attack_tiles > upper.numpy()), 1, 0)\n",
    "inference = np.mean(np.mean(result, axis=1), axis=1)\n",
    "print(inference[0:100])\n",
    "t, th = bf_search(inference, y_test, start=0, end=1, step_num=1000, display_freq=50)"
   ],
   "metadata": {
    "collapsed": false,
    "pycharm": {
     "name": "#%%\n"
    }
   }
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[0.90326797 0.90457516 0.9124183  0.89934641 0.90326797 0.89019608\n",
      " 0.89281046 0.89019608 0.89150327 0.87581699 0.90457516 0.88627451\n",
      " 0.88104575 0.90196078 0.89019608 0.88496732 0.88104575 0.90849673\n",
      " 0.87973856 0.89019608 0.89281046 0.90849673 0.89411765 0.89411765\n",
      " 0.88888889 0.90849673 0.89934641 0.89019608 0.89542484 0.89411765\n",
      " 0.88366013 0.90065359 0.89281046 0.89803922 0.90980392 0.89150327\n",
      " 0.89150327 0.88627451 0.89673203 0.88496732 0.89411765 0.8875817\n",
      " 0.87712418 0.88888889 0.88496732 0.89542484 0.89411765 0.88888889\n",
      " 0.90588235 0.90196078 0.90588235 0.89411765 0.8875817  0.89542484\n",
      " 0.90196078 0.88366013 0.88627451 0.88235294 0.89803922 0.89803922\n",
      " 0.90588235 0.89150327 0.88888889 0.90065359 0.88104575 0.8745098\n",
      " 0.87320261 0.89019608 0.89150327 0.90457516 0.87973856 0.89542484\n",
      " 0.8745098  0.8745098  0.8875817  0.88888889 0.88366013 0.88627451\n",
      " 0.88888889 0.89411765 0.89803922 0.90588235 0.89673203 0.88496732\n",
      " 0.87973856 0.89281046 0.89411765 0.88496732 0.88496732 0.89673203\n",
      " 0.89803922 0.8745098  0.90196078 0.89019608 0.88888889 0.87581699\n",
      " 0.90718954 0.88627451 0.90326797 0.90065359]\n",
      "search range:  0 1\n",
      "cur thr:  0.001 [0.4436272443816195, 0.28504205017516815, 0.9999999964875307, 2847.0, 0.0, 7141.0, 0.0, 0.0] [0.4436272443816195, 0.28504205017516815, 0.9999999964875307, 2847.0, 0.0, 7141.0, 0.0, 0.0] 0.001\n",
      "cur thr:  0.05100000000000004 [0.4436272443816195, 0.28504205017516815, 0.9999999964875307, 2847.0, 0.0, 7141.0, 0.0, 0.0] [0.4436272443816195, 0.28504205017516815, 0.9999999964875307, 2847.0, 0.0, 7141.0, 0.0, 0.0] 0.001\n",
      "cur thr:  0.10100000000000008 [0.4436272443816195, 0.28504205017516815, 0.9999999964875307, 2847.0, 0.0, 7141.0, 0.0, 0.0] [0.4436272443816195, 0.28504205017516815, 0.9999999964875307, 2847.0, 0.0, 7141.0, 0.0, 0.0] 0.001\n",
      "cur thr:  0.1510000000000001 [0.4436272443816195, 0.28504205017516815, 0.9999999964875307, 2847.0, 0.0, 7141.0, 0.0, 0.0] [0.4436272443816195, 0.28504205017516815, 0.9999999964875307, 2847.0, 0.0, 7141.0, 0.0, 0.0] 0.001\n",
      "cur thr:  0.20100000000000015 [0.4436272443816195, 0.28504205017516815, 0.9999999964875307, 2847.0, 0.0, 7141.0, 0.0, 0.0] [0.4436272443816195, 0.28504205017516815, 0.9999999964875307, 2847.0, 0.0, 7141.0, 0.0, 0.0] 0.001\n",
      "cur thr:  0.25100000000000017 [0.4436272443816195, 0.28504205017516815, 0.9999999964875307, 2847.0, 0.0, 7141.0, 0.0, 0.0] [0.4436272443816195, 0.28504205017516815, 0.9999999964875307, 2847.0, 0.0, 7141.0, 0.0, 0.0] 0.001\n",
      "cur thr:  0.3010000000000002 [0.4436272443816195, 0.28504205017516815, 0.9999999964875307, 2847.0, 0.0, 7141.0, 0.0, 0.0] [0.4436272443816195, 0.28504205017516815, 0.9999999964875307, 2847.0, 0.0, 7141.0, 0.0, 0.0] 0.001\n",
      "cur thr:  0.35100000000000026 [0.4436272443816195, 0.28504205017516815, 0.9999999964875307, 2847.0, 0.0, 7141.0, 0.0, 0.0] [0.4436272443816195, 0.28504205017516815, 0.9999999964875307, 2847.0, 0.0, 7141.0, 0.0, 0.0] 0.001\n",
      "cur thr:  0.4010000000000003 [0.4436272443816195, 0.28504205017516815, 0.9999999964875307, 2847.0, 0.0, 7141.0, 0.0, 0.0] [0.4436272443816195, 0.28504205017516815, 0.9999999964875307, 2847.0, 0.0, 7141.0, 0.0, 0.0] 0.001\n",
      "cur thr:  0.45100000000000035 [0.4436272443816195, 0.28504205017516815, 0.9999999964875307, 2847.0, 0.0, 7141.0, 0.0, 0.0] [0.4436272443816195, 0.28504205017516815, 0.9999999964875307, 2847.0, 0.0, 7141.0, 0.0, 0.0] 0.001\n",
      "cur thr:  0.5010000000000003 [0.4436272443816195, 0.28504205017516815, 0.9999999964875307, 2847.0, 0.0, 7141.0, 0.0, 0.0] [0.4436272443816195, 0.28504205017516815, 0.9999999964875307, 2847.0, 0.0, 7141.0, 0.0, 0.0] 0.001\n",
      "cur thr:  0.5510000000000004 [0.4436272443816195, 0.28504205017516815, 0.9999999964875307, 2847.0, 0.0, 7141.0, 0.0, 0.0] [0.4436272443816195, 0.28504205017516815, 0.9999999964875307, 2847.0, 0.0, 7141.0, 0.0, 0.0] 0.001\n",
      "cur thr:  0.6010000000000004 [0.4436272443816195, 0.28504205017516815, 0.9999999964875307, 2847.0, 0.0, 7141.0, 0.0, 0.0] [0.4436272443816195, 0.28504205017516815, 0.9999999964875307, 2847.0, 0.0, 7141.0, 0.0, 0.0] 0.001\n",
      "cur thr:  0.6510000000000005 [0.4436272443816195, 0.28504205017516815, 0.9999999964875307, 2847.0, 0.0, 7141.0, 0.0, 0.0] [0.4436272443816195, 0.28504205017516815, 0.9999999964875307, 2847.0, 0.0, 7141.0, 0.0, 0.0] 0.001\n",
      "cur thr:  0.7010000000000005 [0.4436272443816195, 0.28504205017516815, 0.9999999964875307, 2847.0, 0.0, 7141.0, 0.0, 0.0] [0.4436272443816195, 0.28504205017516815, 0.9999999964875307, 2847.0, 0.0, 7141.0, 0.0, 0.0] 0.001\n",
      "cur thr:  0.7510000000000006 [0.4436272443816195, 0.28504205017516815, 0.9999999964875307, 2847.0, 0.0, 7141.0, 0.0, 0.0] [0.4436272443816195, 0.28504205017516815, 0.9999999964875307, 2847.0, 0.0, 7141.0, 0.0, 0.0] 0.001\n",
      "cur thr:  0.8010000000000006 [0.4436272443816195, 0.28504205017516815, 0.9999999964875307, 2847.0, 0.0, 7141.0, 0.0, 0.0] [0.4436272443816195, 0.28504205017516815, 0.9999999964875307, 2847.0, 0.0, 7141.0, 0.0, 0.0] 0.001\n",
      "cur thr:  0.8510000000000006 [0.4436618110192845, 0.28507059148385844, 0.9999999964875307, 2847.0, 1.0, 7140.0, 0.0, 0.0] [0.4436618110192845, 0.28507059148385844, 0.9999999964875307, 2847.0, 1.0, 7140.0, 0.0, 0.0] 0.8480000000000006\n",
      "cur thr:  0.9010000000000007 [0.7742677574471875, 0.6316840456363789, 0.9999999964875307, 2847.0, 5481.0, 1660.0, 0.0, 8.166530557824036] [0.7742677574471875, 0.6316840456363789, 0.9999999964875307, 2847.0, 5481.0, 1660.0, 0.0, 8.166530557824036] 0.9010000000000007\n",
      "cur thr:  0.9510000000000007 [0.2750657871479928, 0.9999999779735689, 0.15946610411146434, 454.0, 7141.0, 0.0, 2393.0, 75.99240075992401] [0.9244957561634097, 0.8596014466799473, 0.9999999964875307, 2847.0, 6676.0, 465.0, 0.0, 52.16579723671272] 0.9090000000000007\n",
      "[0.9244957561634097, 0.8596014466799473, 0.9999999964875307, 2847.0, 6676.0, 465.0, 0.0, 52.16579723671272] 0.9090000000000007\n"
     ]
    }
   ],
   "source": [
    "result = np.where((attack_tiles < upper.numpy()) | (attack_tiles > lower.numpy()), 1, 0)\n",
    "inference = np.mean(np.mean(result, axis=1), axis=1)\n",
    "print(inference[0:100])\n",
    "t, th = bf_search(inference, y_test, start=0, end=1, step_num=1000, display_freq=50)"
   ],
   "metadata": {
    "collapsed": false,
    "pycharm": {
     "name": "#%%\n"
    }
   }
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[[[0.9814215  0.8842538  0.97994334 ... 0.03057323 0.05085211 0.05523846]\n",
      "  [0.9634274  0.88354987 0.9738182  ... 0.026672   0.06417917 0.04287743]\n",
      "  [0.81425744 0.9056139  0.9370866  ... 0.09821445 0.03014469 0.1096047 ]\n",
      "  ...\n",
      "  [0.967357   0.9117299  0.974082   ... 0.03445207 0.07157819 0.05332107]\n",
      "  [0.91060877 0.7434925  0.8914453  ... 0.09557724 0.08143618 0.18385789]\n",
      "  [0.9292723  0.8870067  0.9612206  ... 0.03414477 0.07568916 0.02669688]]\n",
      "\n",
      " [[0.9107818  0.7585149  0.90382355 ... 0.09205294 0.16748507 0.15060695]\n",
      "  [0.79299325 0.68165755 0.8299092  ... 0.21792054 0.29891777 0.15500174]\n",
      "  [0.6914866  0.8025187  0.8658568  ... 0.19666906 0.14684328 0.14329772]\n",
      "  ...\n",
      "  [0.8279079  0.85081804 0.83305293 ... 0.12272205 0.1959774  0.10196887]\n",
      "  [0.88998646 0.72423244 0.8527468  ... 0.13259816 0.14688675 0.22708566]\n",
      "  [0.95148    0.84784865 0.97377306 ... 0.02876692 0.12866257 0.00825619]]\n",
      "\n",
      " [[0.9207756  0.7818596  0.90413266 ... 0.09629491 0.15099096 0.1526604 ]\n",
      "  [0.7899895  0.6682706  0.8360622  ... 0.22248906 0.27109602 0.14003122]\n",
      "  [0.8848448  0.8656122  0.9044805  ... 0.11704451 0.10441341 0.10761233]\n",
      "  ...\n",
      "  [0.85221916 0.862625   0.7828812  ... 0.0979542  0.16458787 0.08487711]\n",
      "  [0.85972893 0.9170473  0.9699346  ... 0.0297867  0.10164666 0.11385092]\n",
      "  [0.83325666 0.8100816  0.91811866 ... 0.08510743 0.11910912 0.04982079]]\n",
      "\n",
      " ...\n",
      "\n",
      " [[0.9737171  0.8798305  0.96975034 ... 0.02406165 0.07881723 0.05550174]\n",
      "  [0.8362363  0.6728308  0.79379725 ... 0.14184006 0.19336873 0.16233332]\n",
      "  [0.87767017 0.7863545  0.9008135  ... 0.12386587 0.12544627 0.14519423]\n",
      "  ...\n",
      "  [0.8139974  0.6931763  0.71625245 ... 0.25708088 0.3053283  0.25777802]\n",
      "  [0.9520963  0.82191545 0.9743953  ... 0.08146401 0.08504914 0.09200326]\n",
      "  [0.81447035 0.7687637  0.8685422  ... 0.13590196 0.16567615 0.07743171]]\n",
      "\n",
      " [[0.9268371  0.8037261  0.9188336  ... 0.15612361 0.1364654  0.13379216]\n",
      "  [0.9527902  0.7426767  0.9339629  ... 0.04946791 0.05279787 0.06155227]\n",
      "  [0.7850759  0.71457785 0.86351955 ... 0.2192261  0.23555799 0.15959011]\n",
      "  ...\n",
      "  [0.79236877 0.7772351  0.76733667 ... 0.20492968 0.27152935 0.16821782]\n",
      "  [0.9007601  0.7180398  0.9045362  ... 0.14161377 0.16322881 0.19993289]\n",
      "  [0.91156673 0.81755817 0.95636886 ... 0.06611884 0.10261087 0.04976478]]\n",
      "\n",
      " [[0.99014306 0.96212953 0.9873898  ... 0.01996488 0.05052324 0.02623857]\n",
      "  [0.9459513  0.8188906  0.94180626 ... 0.03006555 0.06011578 0.07545263]\n",
      "  [0.74229276 0.8324623  0.83370495 ... 0.17683594 0.10073034 0.16206995]\n",
      "  ...\n",
      "  [0.67863244 0.64083225 0.66738904 ... 0.32143816 0.375197   0.21619295]\n",
      "  [0.85109013 0.9092298  0.95795214 ... 0.02779474 0.10542137 0.13622692]\n",
      "  [0.8806455  0.7516973  0.9242504  ... 0.10837026 0.16312847 0.04763752]]]\n",
      "[[[0.915071   0.7248867  0.94963765 ... 0.01041995 0.03835797 0.01408744]\n",
      "  [0.7461032  0.73376626 0.776915   ... 0.19461857 0.06087383 0.06834646]\n",
      "  [0.7813976  0.61616117 0.8761296  ... 0.11169418 0.11677168 0.17689565]\n",
      "  ...\n",
      "  [0.88883567 0.712471   0.94283015 ... 0.01146786 0.05391859 0.07506191]\n",
      "  [0.9047507  0.7420896  0.9037876  ... 0.03750043 0.03526293 0.03806519]\n",
      "  [0.83466077 0.6865309  0.77277976 ... 0.09511681 0.12929125 0.09713116]]\n",
      "\n",
      " [[0.86029917 0.6836612  0.89154655 ... 0.05257426 0.11284996 0.08802816]\n",
      "  [0.6797619  0.6727335  0.57708895 ... 0.10947143 0.05894417 0.10487494]\n",
      "  [0.8546188  0.63647336 0.9542162  ... 0.03675371 0.02566911 0.07381408]\n",
      "  ...\n",
      "  [0.85170096 0.6629457  0.90965456 ... 0.04323588 0.09090465 0.1159001 ]\n",
      "  [0.8787285  0.6511121  0.86050594 ... 0.05782358 0.05185349 0.08958686]\n",
      "  [0.8098298  0.64135146 0.7944068  ... 0.1599122  0.23557876 0.14316306]]\n",
      "\n",
      " [[0.87388813 0.70397556 0.9187323  ... 0.04631973 0.09830839 0.09027766]\n",
      "  [0.7751844  0.7581439  0.72353685 ... 0.03269287 0.01328874 0.0278658 ]\n",
      "  [0.8862487  0.61133796 0.9590683  ... 0.02934564 0.01937767 0.02085458]\n",
      "  ...\n",
      "  [0.91482884 0.691453   0.9283641  ... 0.05114858 0.21327887 0.0312883 ]\n",
      "  [0.92623484 0.6629951  0.87332135 ... 0.03368314 0.01457524 0.11375628]\n",
      "  [0.92839134 0.69543666 0.79772866 ... 0.04030446 0.07035229 0.05472154]]\n",
      "\n",
      " ...\n",
      "\n",
      " [[0.84598273 0.69595057 0.9109877  ... 0.03932183 0.11411104 0.07024484]\n",
      "  [0.76747406 0.68561226 0.8290854  ... 0.0589092  0.02515011 0.02795092]\n",
      "  [0.9580074  0.76484007 0.9947055  ... 0.0025156  0.0011322  0.00780805]\n",
      "  ...\n",
      "  [0.8878618  0.74873966 0.9500078  ... 0.02297775 0.06816716 0.07254566]\n",
      "  [0.90479386 0.7026826  0.9349564  ... 0.0260063  0.02677487 0.05803229]\n",
      "  [0.87276185 0.62618804 0.8867127  ... 0.06978416 0.10946522 0.08212534]]\n",
      "\n",
      " [[0.8532979  0.6821407  0.8635736  ... 0.04805401 0.10024004 0.06256512]\n",
      "  [0.90224934 0.6088005  0.9615787  ... 0.04367037 0.00617601 0.00358531]\n",
      "  [0.94287646 0.7280726  0.9908789  ... 0.00526061 0.00200429 0.01435622]\n",
      "  ...\n",
      "  [0.8474125  0.5905132  0.86824554 ... 0.06630515 0.13910525 0.11879916]\n",
      "  [0.90572727 0.7237337  0.9327333  ... 0.03290122 0.03302674 0.06191834]\n",
      "  [0.875648   0.7397083  0.79826015 ... 0.14987469 0.14519453 0.07853851]]\n",
      "\n",
      " [[0.93320864 0.70841247 0.92635566 ... 0.01952173 0.06105878 0.01988853]\n",
      "  [0.79223657 0.67581266 0.85466546 ... 0.19621383 0.0779686  0.06801314]\n",
      "  [0.85404336 0.7044142  0.9513286  ... 0.03739902 0.03679648 0.10150294]\n",
      "  ...\n",
      "  [0.8569403  0.64828086 0.9159891  ... 0.02986039 0.0974213  0.11045241]\n",
      "  [0.9088048  0.65922254 0.8527511  ... 0.04115213 0.02502457 0.13444333]\n",
      "  [0.88574207 0.6804041  0.75692904 ... 0.12050351 0.16310321 0.12040433]]]\n"
     ]
    }
   ],
   "source": [
    "a = lower.numpy()\n",
    "b = upper.numpy()\n",
    "print(a)\n",
    "print(b)"
   ],
   "metadata": {
    "collapsed": false,
    "pycharm": {
     "name": "#%%\n"
    }
   }
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "outputs": [],
   "source": [
    "a = a.flatten()\n",
    "b = b.flatten()"
   ],
   "metadata": {
    "collapsed": false,
    "pycharm": {
     "name": "#%%\n"
    }
   }
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "outputs": [],
   "source": [
    "aUb, aLb, eq = [], [], []\n",
    "for i in range(len(a)):\n",
    "    if a[i] > b[i]:\n",
    "        aUb.append(i)\n",
    "    elif a[i] < b[i]:\n",
    "        aLb.append(i)\n",
    "    else:\n",
    "        eq.append(i)"
   ],
   "metadata": {
    "collapsed": false,
    "pycharm": {
     "name": "#%%\n"
    }
   }
  },
  {
   "cell_type": "code",
   "execution_count": 21,
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "5775159\n",
      "1865661\n",
      "0\n"
     ]
    }
   ],
   "source": [
    "# print(aUb)\n",
    "# print(aLb)\n",
    "# print(eq)\n",
    "print(len(aUb))\n",
    "print(len(aLb))\n",
    "print(len(eq))"
   ],
   "metadata": {
    "collapsed": false,
    "pycharm": {
     "name": "#%%\n"
    }
   }
  }
 ],
 "metadata": {
  "accelerator": "GPU",
  "colab": {
   "name": "USAD_test.ipynb",
   "provenance": [],
   "toc_visible": true
  },
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.6.8"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 1
}